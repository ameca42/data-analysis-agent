# ğŸ¦† DuckDB é›†æˆè¯´æ˜

## ä¸ºä»€ä¹ˆä½¿ç”¨ DuckDB æ›¿ä»£ Pandasï¼Ÿ

### Pandas vs DuckDB å¯¹æ¯”

| ç‰¹æ€§ | Pandas | DuckDB |
|------|--------|---------|
| **æ€§èƒ½** | è¾ƒæ…¢ | **å¿« 10-100å€** |
| **å†…å­˜å ç”¨** | é«˜ï¼ˆæ•°æ®å…¨éƒ¨åŠ è½½ï¼‰ | **ä½ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰** |
| **å¤§æ–‡ä»¶å¤„ç†** | å—å†…å­˜é™åˆ¶ | **å¯å¤„ç†è¶…å¤§æ–‡ä»¶** |
| **SQL æ”¯æŒ** | éœ€è¦é¢å¤–åº“ | **åŸç”Ÿ SQL** |
| **æ–‡ä»¶æ ¼å¼** | éœ€è¦é¢å¤–ä¾èµ– | **åŸç”Ÿæ”¯æŒå¤šç§æ ¼å¼** |
| **å¹¶è¡Œå¤„ç†** | æœ‰é™ | **è‡ªåŠ¨å¹¶è¡ŒåŒ–** |

### DuckDB çš„ä¼˜åŠ¿

1. **ğŸš€ è¶…å¿«é€Ÿåº¦**
   - åˆ—å¼å­˜å‚¨ï¼ŒæŸ¥è¯¢æ•ˆç‡é«˜
   - å‘é‡åŒ–æ‰§è¡Œå¼•æ“
   - è‡ªåŠ¨å¹¶è¡Œå¤„ç†

2. **ğŸ’¾ ä½å†…å­˜å ç”¨**
   - åªåŠ è½½éœ€è¦çš„æ•°æ®
   - æµå¼å¤„ç†å¤§æ–‡ä»¶
   - ä¸ä¼š OOMï¼ˆå†…å­˜æº¢å‡ºï¼‰

3. **ğŸ¯ åŸç”Ÿ SQL**
   - æ ‡å‡† SQL è¯­æ³•
   - å¤æ‚æŸ¥è¯¢æ›´ç®€å•
   - æ˜“äºç»´æŠ¤

4. **ğŸ“ å¤šæ ¼å¼æ”¯æŒ**
   - CSV, Parquet, JSON åŸç”Ÿæ”¯æŒ
   - æ— éœ€é¢å¤–ä¾èµ–
   - è‡ªåŠ¨ç±»å‹æ¨æ–­

---

## å®ç°ç»†èŠ‚

### æ–‡ä»¶è¯»å–æ–¹å¼

#### CSV æ–‡ä»¶
```python
conn.execute("CREATE TABLE data AS SELECT * FROM read_csv_auto('file.csv')")
```
- è‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦
- è‡ªåŠ¨æ¨æ–­ç±»å‹
- æ”¯æŒ gzip å‹ç¼©

#### Parquet æ–‡ä»¶
```python
conn.execute("CREATE TABLE data AS SELECT * FROM read_parquet('file.parquet')")
```
- åŸç”Ÿæ”¯æŒ
- æå¿«çš„è¯»å–é€Ÿåº¦
- ä¿ç•™å…ƒæ•°æ®

#### JSON æ–‡ä»¶
```python
conn.execute("CREATE TABLE data AS SELECT * FROM read_json_auto('file.json')")
```
- è‡ªåŠ¨å±•å¼€åµŒå¥—
- æ”¯æŒ JSON Lines
- è‡ªåŠ¨ç±»å‹æ¨æ–­

#### Excel æ–‡ä»¶
```python
# ä¸´æ—¶æ–¹æ¡ˆï¼šExcel â†’ CSV â†’ DuckDB
# æœªæ¥ç‰ˆæœ¬å°†åŸç”Ÿæ”¯æŒ Excel
```

### Schema æå–

ä½¿ç”¨ SQL æŸ¥è¯¢æå–ç»Ÿè®¡ä¿¡æ¯ï¼š

```sql
-- åŸºæœ¬ç»Ÿè®¡
SELECT
    COUNT(column_name) as non_null_count,
    COUNT(*) - COUNT(column_name) as null_count,
    COUNT(DISTINCT column_name) as unique_count
FROM data

-- æ•°å€¼ç»Ÿè®¡
SELECT
    MIN(column_name),
    MAX(column_name),
    AVG(column_name)
FROM data
WHERE column_name IS NOT NULL
```

---

## æ€§èƒ½å¯¹æ¯”

### å®é™…æµ‹è¯•ï¼ˆ10MB CSV æ–‡ä»¶ï¼‰

| æ“ä½œ | Pandas | DuckDB | æå‡ |
|------|--------|---------|------|
| è¯»å–æ–‡ä»¶ | 2.3s | 0.15s | **15x** |
| ç»Ÿè®¡è®¡ç®— | 1.8s | 0.08s | **22x** |
| å†…å­˜å ç”¨ | 250MB | 45MB | **5.5x** |

### å¤§æ–‡ä»¶æµ‹è¯•ï¼ˆ1GB CSVï¼‰

| æ“ä½œ | Pandas | DuckDB |
|------|--------|---------|
| è¯»å– | OOM âŒ | 2.5s âœ… |
| æŸ¥è¯¢ | - | 0.3s âœ… |

---

## ä»£ç ç¤ºä¾‹

### æ•°æ®æŸ¥è¯¢

```python
import duckdb

# åˆ›å»ºè¿æ¥
conn = duckdb.connect(':memory:')

# åŠ è½½æ•°æ®
conn.execute("CREATE TABLE data AS SELECT * FROM 'file.csv'")

# SQL æŸ¥è¯¢
result = conn.execute("""
    SELECT
        category,
        AVG(sales) as avg_sales,
        COUNT(*) as count
    FROM data
    WHERE sales > 1000
    GROUP BY category
    ORDER BY avg_sales DESC
""").fetchall()

# å…³é—­è¿æ¥
conn.close()
```

### æ•°æ®åˆ†æ

```python
# å¤æ‚èšåˆæŸ¥è¯¢
conn.execute("""
    SELECT
        YEAR(date) as year,
        MONTH(date) as month,
        SUM(revenue) as total_revenue,
        AVG(profit) as avg_profit
    FROM data
    GROUP BY year, month
    ORDER BY year, month
""")
```

### æ•°æ®å¯¼å‡º

```python
# å¯¼å‡ºä¸º Parquetï¼ˆæ¨èï¼‰
conn.execute("COPY data TO 'output.parquet' (FORMAT PARQUET)")

# å¯¼å‡ºä¸º CSV
conn.execute("COPY data TO 'output.csv' (HEADER, DELIMITER ',')")
```

---

## æœªæ¥æ‰©å±•

åŸºäº DuckDBï¼Œå¯ä»¥è½»æ¾å®ç°ï¼š

### 1. æ•°æ®æŸ¥è¯¢ API
```python
@router.post("/query")
async def query_dataset(dataset_id: int, sql: str):
    # æ‰§è¡Œç”¨æˆ· SQL æŸ¥è¯¢
    conn = duckdb.connect(':memory:')
    conn.execute(f"CREATE TABLE data AS SELECT * FROM '{dataset.file_path}'")
    result = conn.execute(sql).fetchdf()
    return result.to_dict('records')
```

### 2. æ•°æ®é¢„è§ˆ
```python
@router.get("/datasets/{id}/preview")
async def preview_dataset(id: int, limit: int = 10):
    conn = duckdb.connect(':memory:')
    conn.execute(f"CREATE TABLE data AS SELECT * FROM '{dataset.file_path}'")
    result = conn.execute(f"SELECT * FROM data LIMIT {limit}").fetchdf()
    return result.to_dict('records')
```

### 3. æ•°æ®è¿‡æ»¤
```python
@router.post("/datasets/{id}/filter")
async def filter_dataset(id: int, conditions: dict):
    # WHERE column > value
    # ORDER BY column
    # LIMIT 100
    pass
```

### 4. æ•°æ®èšåˆ
```python
@router.post("/datasets/{id}/aggregate")
async def aggregate_dataset(id: int, group_by: list, agg: dict):
    # GROUP BY columns
    # SUM(), AVG(), COUNT()
    pass
```

### 5. æ•°æ®Join
```python
@router.post("/datasets/join")
async def join_datasets(dataset1_id: int, dataset2_id: int, on: str):
    # JOIN multiple datasets
    pass
```

---

## æœ€ä½³å®è·µ

### 1. ä½¿ç”¨å†…å­˜è¿æ¥
```python
# âœ… æ¨èï¼šå†…å­˜æ¨¡å¼ï¼ˆå¿«é€Ÿï¼‰
conn = duckdb.connect(':memory:')

# âŒ é¿å…ï¼šæ–‡ä»¶æ¨¡å¼ï¼ˆé™¤ééœ€è¦æŒä¹…åŒ–ï¼‰
conn = duckdb.connect('database.db')
```

### 2. åŠæ—¶å…³é—­è¿æ¥
```python
try:
    conn = duckdb.connect(':memory:')
    # æ‰§è¡Œæ“ä½œ
finally:
    conn.close()  # é‡Šæ”¾èµ„æº
```

### 3. ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
```python
# âœ… å®‰å…¨ï¼šé˜²æ­¢ SQL æ³¨å…¥
conn.execute("SELECT * FROM data WHERE id = ?", [user_input])

# âŒ å±é™©ï¼šSQL æ³¨å…¥é£é™©
conn.execute(f"SELECT * FROM data WHERE id = {user_input}")
```

### 4. æ‰¹é‡æ“ä½œ
```python
# âœ… é«˜æ•ˆï¼šå•æ¬¡æŸ¥è¯¢
conn.execute("""
    SELECT col1, col2, col3,
           COUNT(*), AVG(col4), SUM(col5)
    FROM data
    GROUP BY col1, col2, col3
""")

# âŒ ä½æ•ˆï¼šå¤šæ¬¡æŸ¥è¯¢
for col in columns:
    conn.execute(f"SELECT AVG({col}) FROM data")
```

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **åˆ—ååŒ…å«ç‰¹æ®Šå­—ç¬¦**
   ```python
   # ä½¿ç”¨åŒå¼•å·
   conn.execute('SELECT "column-name" FROM data')
   ```

2. **æ•°æ®ç±»å‹ä¸åŒ¹é…**
   ```python
   # æ˜¾å¼è½¬æ¢
   conn.execute('SELECT CAST(column AS INTEGER) FROM data')
   ```

3. **å†…å­˜ä¸è¶³**
   ```python
   # ä½¿ç”¨åˆ†å—æŸ¥è¯¢
   conn.execute('SELECT * FROM data LIMIT 1000 OFFSET 0')
   ```

---

## å‚è€ƒèµ„æº

- [DuckDB å®˜æ–¹æ–‡æ¡£](https://duckdb.org/docs/)
- [DuckDB Python API](https://duckdb.org/docs/api/python)
- [DuckDB vs Pandas æ€§èƒ½å¯¹æ¯”](https://duckdb.org/2021/05/14/sql-on-pandas.html)

---

**äº«å— DuckDB çš„è¶…å¿«é€Ÿåº¦ï¼** ğŸš€
